{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code structure:   \n",
    "annotation file structure:\n",
    "\n",
    "    onset, class-value , duration \n",
    "    20.321666667,3,0.059166667\n",
    "    20.424,3,0.093\n",
    "    20.600333333,3,0.107\n",
    "\n",
    "\n",
    "1 open annotation and corresponding wav file\n",
    "\n",
    "2 split audio file into segments, \n",
    "\n",
    "3 feature extraction for each segment - mel spectrograms for now, \n",
    "\n",
    "4 read annotations and create label for each segment \n",
    "\n",
    "\n",
    "--> class-value key:\n",
    "\n",
    "        1- Male inhale\n",
    "        2- Female inhale\n",
    "        3- Chick\n",
    "        4- Male bout\n",
    "        5- Female bout\n",
    "        6- Flapping\n",
    "        7- Male grunt/noise\n",
    "        8- Female grunt/noise\n",
    "        9- Unknown grunt/noise\n",
    "\n",
    "5 create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_raw_annotations_file(raw_file_name, annotations_file_path, labels_dict):\n",
    "\n",
    "    processed_annotations = []\n",
    "#     processed_annotation_filename =raw_file_name[0:-4]+'_processed.npy'\n",
    "    \n",
    "    if os.path.isfile(annotations_file_path + raw_file_name):\n",
    "        \n",
    "        with open(annotations_file_path + raw_file_name, 'r') as rawfile:\n",
    "            reader = csv.reader(rawfile)\n",
    "            \n",
    "            for row in reader:\n",
    "\n",
    "                onset_sec = float(row[0])\n",
    "                try:\n",
    "                    label_value = int(row[1])\n",
    "                except ValueError as e:\n",
    "                    print(\"annotation error, will make it as closest label!\")\n",
    "                    label_value = int(np.floor(1.5))\n",
    "                    \n",
    "                try:\n",
    "                    label_str = labels_dict[label_value]\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                duration_sec = float(row[2])\n",
    "                offset_sec =  onset_sec + duration_sec\n",
    "\n",
    "                processed_annotations.append([onset_sec, offset_sec, label_str])\n",
    "            \n",
    "#     if save_path:\n",
    "# #         save the processed annotation:\n",
    "#         data_array = np.asarray(processed_annotations)\n",
    "#         np.save(processed_annotation_filename, data_array) \n",
    "            \n",
    "            \n",
    "    return processed_annotations\n",
    "\n",
    "def get_label_matrix_per_segment(start_sec, end_sec, sr, timesteps, timesteps_per_second, annotations_list, labels_dict ):\n",
    "    \n",
    "    ldict = dict([[v,k] for k,v in labels_dict.items()])\n",
    "    nb_classes = len(ldict.keys())\n",
    "    label_matrix = np.zeros((nb_classes, timesteps))\n",
    "    \n",
    "    for onset_sec, offset_sec, label in annotations_list:\n",
    "\n",
    "        # go trhough anotations file and check if any onset or offset is inside start-to-end period\n",
    "        if (start_sec <= onset_sec and end_sec >= onset_sec) or (start_sec <= offset_sec and end_sec >= offset_sec):\n",
    "            \n",
    "            onset_timeframe_index =  np.floor((onset_sec - start_sec )*timesteps_per_second)\n",
    "            offset_timeframe_index = np.ceil((offset_sec - start_sec )*timesteps_per_second)\n",
    "            \n",
    "#             print(onset_timeframe_index)\n",
    "#             print(onset_sec)\n",
    "#             print(offset_timeframe_index)\n",
    "#             print(offset_sec)\n",
    "            print(label +' '+str(int(ldict[label])-1))\n",
    "           \n",
    "            try:\n",
    "                label_matrix[int(ldict[label])-1][int(round(onset_timeframe_index)):int(round(offset_timeframe_index))] = 1\n",
    "            except Exception as e:\n",
    "                pdb.set_trace()\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return label_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/wavs/\"\n",
    "save_path = \"/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/\"\n",
    "annotations_path = \"/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/Annotations/\"\n",
    "\n",
    "labels_dict = {1:'male_in', 2:'female_in', 3:'chick', 4:'male_bout', 5:'female_bout', 6:'flapping', 7: 'male_grunt', 8:'female_grunt', 9:'unk_grunt' }\n",
    "\n",
    "\n",
    "segment_size = 6\n",
    "slide = 6\n",
    "mels = 64\n",
    "sample_rate = 22_050\n",
    "timesteps = 259 # number of frames in a segment! =((SR* segment_size)/ hop_length)\n",
    "timesteps_per_second = timesteps / segment_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "dataset = [] # [dt_id, spectrogram, labelmatrix]\n",
    "\n",
    "for audio_file in tqdm(os.listdir(audio_path), desc='load_audio'):\n",
    "    print('load audio')\n",
    "    dataset_per_file = []\n",
    "    y, sr = librosa.load(audio_path+audio_file, sr=sample_rate)\n",
    "    length = int(len(y) / sr) #seconds\n",
    "    remainder = length % segment_size\n",
    "    #     import pdb; pdb.set_trace()\n",
    "\n",
    "    audio_id = audio_file[:-4]\n",
    "\n",
    "    raw_annotation_file = audio_id  + '_a.csv'\n",
    "\n",
    "    processed_annotations = process_raw_annotations_file(raw_annotation_file, annotations_path, labels_dict)    \n",
    "\n",
    "    for t in tqdm(range(0, length - remainder - segment_size, slide),\n",
    "                  desc='create_spectros'):\n",
    "        start = t\n",
    "    #         print('start', str(start))\n",
    "        stop = t + segment_size\n",
    "\n",
    "        print('start in frames', str(sr*start))\n",
    "        print('stop in frames: ', str((sr*stop)))\n",
    "\n",
    "        current_y = y[sr*start:(sr*stop)]\n",
    "        # create spectrogram\n",
    "        spectro = librosa.feature.melspectrogram(y=current_y, sr=sr, n_mels=mels,\n",
    "                                                 fmax=sr/2)\n",
    "\n",
    "        dt_id = audio_id + '_' + str(start) + 's_to' + str(stop) + 's'\n",
    "        print(dt_id)\n",
    "\n",
    "        label_matrix = get_label_matrix_per_segment(start, stop, sr, timesteps, timesteps_per_second, processed_annotations, labels_dict )\n",
    "        dataset_per_file.append([dt_id, spectro, label_matrix])\n",
    "        dataset.append([dt_id, spectro, label_matrix])\n",
    "        \n",
    "    \n",
    "    #save data processed for this file\n",
    "    d_array = np.asarray(dataset_per_file)\n",
    "    np.save(save_path+audio_id, d_array)\n",
    "\n",
    "data_array = np.asarray(dataset)\n",
    "np.save(save_path+'data_25_03', data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.floor(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for file in os.listdir('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/'):\n",
    "#     print(file)\n",
    "    data = np.load('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/' + file, allow_pickle=True)\n",
    "#     print(data.shape)\n",
    "    dataset.extend(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_array = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38049, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/dataset_25_03.npy', dataset_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
