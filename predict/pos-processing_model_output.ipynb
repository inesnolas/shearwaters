{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create regions file from segment predictions matrices:\n",
    "    \n",
    "   #### predictions are saved as:\n",
    "    \n",
    "        [audio_id_segm_start_sec_to_end_sec, array shape(n_target classes, number of frames (6 sec segm = 259 timeframes))]\n",
    "        \n",
    "        \n",
    "   #### region file structure:\n",
    "    \n",
    "    onset(sec), class_value, duration(sec)\n",
    "        \n",
    "\n",
    "for each predictions file :\n",
    "\n",
    "(NEAT would be to make this as a parallel process that alwys looks into a folder and starts this as the files become available check this: https://askubuntu.com/questions/781799/execution-permission-to-all-files-created-under-a-specific-directory-by-default/781909#781909)\n",
    "        \n",
    "        for each row:\n",
    "            check if any 1 (any positive predictions) and what row it apears in!\n",
    "               Get start_segment\n",
    "               for each row identified above:\n",
    "                   onset0 = start_segment + frame_index 1st 1 transformed to sec\n",
    "                   class_value = row\n",
    "                   duration = number frames of continuous 1s, transformed into sec.\n",
    "                   \n",
    "                   There maybe other events!\n",
    "                       identify plasces where seq of 1s started again. . . . .\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import csv\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size = 6\n",
    "timesteps = 259 # number of frames in a segment! =((SR* segment_size)/ hop_length)\n",
    "timesteps_per_second = timesteps / segment_size\n",
    "\n",
    "\n",
    "####################################################\n",
    "#define which files are going to be processed. each prediction_file corresponds to a whole audio file.\n",
    "prediction_files_path = \"testing_apply_model/\"\n",
    "predictions_files = os.listdir('testing_apply_model')\n",
    "# save_path = prediction_files_path + 'region_files/'\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n",
    "for pfile in predictions_files:\n",
    "    regions_csv = []\n",
    "    print(pfile)\n",
    "    \n",
    "    #load pfile into np array\n",
    "    predict_array = np.load(prediction_files_path + pfile, allow_pickle=True)  \n",
    "    for segm_id, predict_matrix in predict_array: #check shape of each predict_matrix is (3,259)      \n",
    "        predict_matrix = predict_matrix.reshape(3,259)\n",
    "#         print(segm_id)\n",
    "#         print(predict_matrix.shape)\n",
    "        # no point in continuing if the whole matrix is zeros!\n",
    "        if not predict_matrix.any():\n",
    "#             print(segm_id)\n",
    "            continue\n",
    "    \n",
    "#     ERROR here, or are my files really without any detections??\n",
    "    \n",
    "    \n",
    "    \n",
    "        else:\n",
    "            #get start segm in sec\n",
    "            start_sec = int(segm_id.split('s_to')[0].split('_')[-1])\n",
    "#             print(\"start_sec\", start_sec)\n",
    "\n",
    "            for class_value in range(predict_matrix.shape[0]):\n",
    "#                 print(class_value)\n",
    "                seq = predict_matrix[class_value,:]\n",
    "                summary_seq = [(k, sum(1 for _ in i)) for k, i in it.groupby(seq)]\n",
    "#                 print(\"summary_seq\", summary_seq)\n",
    "                #example:\n",
    "\n",
    "                    # >>> seq = [0,0,0,0,0,1,1,1,1,0,1,1,1,1]\n",
    "                    # >>> summary_seq = [(k,sum(1 for _ in i)) for k, i in it.groupby(seq)]\n",
    "                    #  [(0, 5), (1, 4), (0, 1), (1, 4)]\n",
    "\n",
    "\n",
    "                summary_seq_with_start_pos = list(range(len(summary_seq)))\n",
    "\n",
    "                for i, t in enumerate(summary_seq):\n",
    "                    if i == 0: #first seq gets position 0\n",
    "                        summary_seq_with_start_pos[0] = (summary_seq[0],0) \n",
    "                    else:  # all others get start position = previous seq start_position+duration!\n",
    "                        summary_seq_with_start_pos[i] = (summary_seq[i], summary_seq_with_start_pos[i-1][-1] + summary_seq[i-1][1])                        \n",
    "            #             print(\"summary_seq_with_start_pos[i]\", summary_seq_with_start_pos[i])\n",
    "            #             print(\"summary_seq_with_start_pos[i-1][-1] + summary_seq[i-1][1]\", summary_seq_with_start_pos[i-1][-1]+ summary_seq[i-1][1])\n",
    "\n",
    "\n",
    "#                 print(\"summary_seq_with_start_pos\", summary_seq_with_start_pos)\n",
    "\n",
    "                summary_seq_with_start_pos_events_only = [t  for t in summary_seq_with_start_pos if t[0][0] ==1]\n",
    "#                 print(\"summary_seq_with_start_pos_events_only\", summary_seq_with_start_pos_events_only)\n",
    "\n",
    "                nb_distinct_events = len(summary_seq_with_start_pos_events_only)\n",
    "#                 print(\"nb_distinct_events\", nb_distinct_events)\n",
    "                for e in range(nb_distinct_events):\n",
    "                    onset = start_sec + summary_seq_with_start_pos_events_only[e][-1] * 1/timesteps_per_second #get start position in sec\n",
    "                    duration = summary_seq_with_start_pos_events_only[e][0][-1] * 1/timesteps_per_second   #get duration in sec\n",
    "\n",
    "                    regions_csv.append([onset, class_value, duration])\n",
    "        print(regions_csv)\n",
    "\n",
    "        ########################\n",
    "        #Join contiguos events separated due to segmentation !!! maybe is not a problem.. but would be better!\n",
    "        ###################\n",
    "        \n",
    "        \n",
    "        #save regions_csv for this audiofile:             \n",
    "        with open(pfile[:-4]+'.csv', 'w', newline='') as tfile:\n",
    "            writer = csv.writer(tfile)\n",
    "            for r in regions_csv:\n",
    "                writer.writerow(r)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  test= np.load(prediction_files_path + predictions_files[0], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test[0,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_mats = test[:,-1]\n",
    "# print(pred_mats[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_mat = np.sum(pred_mats)\n",
    "# test_pred_mat = test_pred_mat.reshape(3,259)\n",
    "\n",
    "# print(test_pred_mat.shape)   #same shape of 1 pred mat! cool and it actually has stuff...\n",
    "# print(test_pred_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if test_pred_mat.all():\n",
    "#     print('didnt detect')\n",
    "# else:\n",
    "#     print(\"yeay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_sec = 0\n",
    "# print(\"start_sec\", start_sec)\n",
    "# regions_csv = []\n",
    "\n",
    "# for class_value in range(test_pred_mat.shape[0]):\n",
    "#     print(\"class_value\", class_value)\n",
    "#     seq = test_pred_mat[class_value,:]\n",
    "#     print(\"seq\", seq)\n",
    "#     summary_seq = [(k, sum(1 for _ in i)) for k, i in it.groupby(seq)]\n",
    "#     print(\"summary_seq\", summary_seq)\n",
    "#     #example:\n",
    "\n",
    "#         # >>> seq = [0,0,0,0,0,1,1,1,1,0,1,1,1,1]\n",
    "#         # >>> summary_seq = [(k,sum(1 for _ in i)) for k, i in it.groupby(seq)]\n",
    "#         #  [(0, 5), (1, 4), (0, 1), (1, 4)]\n",
    "\n",
    "\n",
    "#     summary_seq_with_start_pos = list(range(len(summary_seq)))\n",
    "    \n",
    "#     for i, t in enumerate(summary_seq):\n",
    "#         if i == 0: #first seq gets position 0\n",
    "#             summary_seq_with_start_pos[0] = (summary_seq[0],0) \n",
    "#         else:  # all others get start position = previous seq start_position+duration!\n",
    "#             summary_seq_with_start_pos[i] = (summary_seq[i], summary_seq_with_start_pos[i-1][-1] + summary_seq[i-1][1])                        \n",
    "# #             print(\"summary_seq_with_start_pos[i]\", summary_seq_with_start_pos[i])\n",
    "# #             print(\"summary_seq_with_start_pos[i-1][-1] + summary_seq[i-1][1]\", summary_seq_with_start_pos[i-1][-1]+ summary_seq[i-1][1])\n",
    "        \n",
    "            \n",
    "#     print(\"summary_seq_with_start_pos\", summary_seq_with_start_pos)\n",
    "        \n",
    "#     summary_seq_with_start_pos_events_only = [t  for t in summary_seq_with_start_pos if t[0][0] ==1]\n",
    "#     print(\"summary_seq_with_start_pos_events_only\", summary_seq_with_start_pos_events_only)\n",
    "    \n",
    "#     nb_distinct_events = len(summary_seq_with_start_pos_events_only)\n",
    "#     print(\"nb_distinct_events\", nb_distinct_events)\n",
    "#     for e in range(nb_distinct_events):\n",
    "#         onset = start_sec + summary_seq_with_start_pos_events_only[e][-1] * 1/timesteps_per_second #get start position in sec\n",
    "#         duration = summary_seq_with_start_pos_events_only[e][0][-1] * 1/timesteps_per_second   #get duration in sec\n",
    "\n",
    "#         regions_csv.append([onset, class_value, duration])\n",
    "# print(regions_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
