{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to load and treat data to feed into model, \n",
    "ideally make them for both batch (ofline) and online "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_root_path = \"/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/\n",
    "\n",
    "audio_path = where_root_path + \"data/wavs/\"\n",
    "save_path = where_root_path + \"data/data_predictions_processed/\"\n",
    "\n",
    "segment_size = 6\n",
    "slide = 6\n",
    "mels = 64\n",
    "sample_rate = 22_050\n",
    "timesteps = 259 # number of frames in a segment! =((SR* segment_size)/ hop_length)\n",
    "timesteps_per_second = timesteps / segment_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_compute_spectrogram(list_audio_files,segment_size, slide, mels, sample_rate ):\n",
    "    for audio_file in tqdm(list_audio_files), desc='load_audio'):\n",
    "    y, sr = librosa.load(audio_path+audio_file, sr=sample_rate)\n",
    "    dataset_per_file = []\n",
    "    length = int(len(y) / sr) #seconds\n",
    "    remainder = length % segment_size\n",
    "    \n",
    "    return \n",
    "\n",
    "# dataset = [] # [dt_id, spectrogram]\n",
    "\n",
    "# for audio_file in tqdm(os.listdir(audio_path), desc='load_audio'):\n",
    "    print('load audio')\n",
    "    dataset_per_file = []\n",
    "    y, sr = librosa.load(audio_path+audio_file, sr=sample_rate)\n",
    "    length = int(len(y) / sr) #seconds\n",
    "    remainder = length % segment_size\n",
    "    #     import pdb; pdb.set_trace()\n",
    "\n",
    "    audio_id = audio_file[:-4]\n",
    "\n",
    "    raw_annotation_file = audio_id  + '_a.csv'\n",
    "\n",
    "    processed_annotations = process_raw_annotations_file(raw_annotation_file, annotations_path, labels_dict)    \n",
    "\n",
    "    for t in tqdm(range(0, length - remainder - segment_size, slide),\n",
    "                  desc='create_spectros'):\n",
    "        start = t\n",
    "    #         print('start', str(start))\n",
    "        stop = t + segment_size\n",
    "\n",
    "        print('start in frames', str(sr*start))\n",
    "        print('stop in frames: ', str((sr*stop)))\n",
    "\n",
    "        current_y = y[sr*start:(sr*stop)]\n",
    "        # create spectrogram\n",
    "        spectro = librosa.feature.melspectrogram(y=current_y, sr=sr, n_mels=mels,\n",
    "                                                 fmax=sr/2)\n",
    "\n",
    "        dt_id = audio_id + '_' + str(start) + 's_to' + str(stop) + 's'\n",
    "        print(dt_id)\n",
    "\n",
    "        label_matrix = get_label_matrix_per_segment(start, stop, sr, timesteps, timesteps_per_second, processed_annotations, labels_dict )\n",
    "        dataset_per_file.append([dt_id, spectro, label_matrix])\n",
    "        dataset.append([dt_id, spectro, label_matrix])\n",
    "        \n",
    "    \n",
    "    #save data processed for this file\n",
    "    d_array = np.asarray(dataset_per_file)\n",
    "    np.save(save_path+audio_id, d_array)\n",
    "\n",
    "data_array = np.asarray(dataset)\n",
    "np.save(save_path+'data_25_03', data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for file in os.listdir('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/'):\n",
    "#     print(file)\n",
    "    data = np.load('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/' + file, allow_pickle=True)\n",
    "#     print(data.shape)\n",
    "    dataset.extend(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_array = np.asarray(dataset)\n",
    "np.save('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/dataset_25_03.npy', dataset_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit6c3ee278afa641b192a9247d08aa1230"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
