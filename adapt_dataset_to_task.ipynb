{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code structure:   \n",
    "i want to adappt and create a subdataset for different tasks,\n",
    "    this comprises: joining labels together, \n",
    "    filtering out some classes\n",
    "    or selecting others only. \n",
    "    \n",
    "    \n",
    "1 - load dataset:\n",
    "    structure is:\n",
    "        segmentID, spectrogram, matrixlabel (9*259) each row corresponds to the following classes\n",
    "                    \n",
    "        1- Male inhale\n",
    "        2- Female inhale\n",
    "        3- Chick\n",
    "        4- Male bout\n",
    "        5- Female bout\n",
    "        6- Flapping\n",
    "        7- Male grunt/noise\n",
    "        8- Female grunt/noise\n",
    "        9- Unknown grunt/noise\n",
    "\n",
    "2 - define manipulation to do\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_label(dataset,labels_dict, new_labels_dict  ):\n",
    "    '''remove classes from label_matrix '''\n",
    "    inve_new_label_dict = {v: k for k, v in new_labels_dict.items()}\n",
    "    inv_labels_dic = {v: k for k, v in labels_dict.items()} \n",
    "    \n",
    "    \n",
    "    new_dataset = []\n",
    "    for segm_id, spectro, label_matrix in dataset:\n",
    "        new_label_matrix = np.zeros((len(new_labels_dict.keys()), 259))\n",
    "        for lb, new_indx  in inve_new_label_dict.items():\n",
    "            new_label_matrix[new_indx,:] = label_matrix[inv_labels_dic[lb]]\n",
    "        \n",
    "        new_dataset.append([segm_id, spectro, new_label_matrix])\n",
    "\n",
    "    new_dataset = np.asarray(new_dataset)\n",
    "    return new_dataset, new_labels_dict\n",
    "\n",
    "def join_labels(labels_2_join, dataset, labels_dict, new_labels_dict, new_class_label):\n",
    "    '''join information in different rows,   and create aditional row for joint labels\n",
    "    '''\n",
    "        \n",
    "    inve_new_label_dict = {v: k for k, v in new_labels_dict.items()}\n",
    "    inv_labels_dic = {v: k for k, v in labels_dict.items()}\n",
    "    labels_2_join_indx = []\n",
    "    for label in labels_2_join:\n",
    "        labels_2_join_indx.append(inv_labels_dic[label])\n",
    "        # based on labels_dict!\n",
    "\n",
    "    new_dataset = []\n",
    "\n",
    "\n",
    "    for segm_id, spectro, label_matrix in dataset:\n",
    "        \n",
    "        new_label_matrix = np.zeros((len(new_labels_dict.keys()), 259))\n",
    "        new_label_matrix[0:label_matrix.shape[0], :] = label_matrix\n",
    "\n",
    "        joined_labels_row = np.sum(label_matrix[labels_2_join_indx, :],0)\n",
    "        #just normalizing to 1s and zeros...\n",
    "        joined_labels_row = np.divide(joined_labels_row, joined_labels_row, out=np.zeros_like(joined_labels_row), where=joined_labels_row!=0)\n",
    "        \n",
    "        indx = inve_new_label_dict[new_class_label]\n",
    "        new_label_matrix[int(indx),:] = joined_labels_row\n",
    "\n",
    "        new_dataset.append([segm_id, spectro, new_label_matrix])\n",
    "\n",
    "    new_dataset = np.asarray(new_dataset)\n",
    "    return new_dataset, new_labels_dict\n",
    "\n",
    "\n",
    "def select_examples_based_labels(dataset, positive_labels, labels_dict, mode='keepPosOnly' ):\n",
    "    '''keepPosOnly: keep only examples that have ones in the given rows (positive_labels) \n",
    "    (remove everything else or the ones that have on;ly zeros!)\n",
    "        \n",
    "        keepNegOnly: keep only examples that have ones only onm other rows than the ones \n",
    "    defined as positive!\n",
    "        \n",
    "        keepSilencesOnly: select examples that have zeros through the whole matrix! \n",
    "    (becareful between the distinction of negs and silences depends on the dataset given!)\n",
    "    \n",
    "    '''        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return sub_dataset\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = '/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/'\n",
    "\n",
    "labels_dict = {0:'male_in', 1:'female_in', 2:'chick', 3:'male_bout', 4:'female_bout', 5:'flapping', 6: 'male_grunt', 7:'female_grunt', 8:'unk_grunt' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(data_processed+'dataset_25_03.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult_vs_chick_dataset:\n",
    "\n",
    "# lets create dataset with the following 3 classes: Adult_bouts, chicks and adult_grunts\n",
    "\n",
    "#0- get silences dataset\n",
    "#1 - join female_bouts and male bouts into adult_bouts_class\n",
    "# 2 - join the 3 grunt classes into adult_grunts (fem_grunt, male_grunt, unk_grunt)\n",
    "# 3 - remove all other classes\n",
    "\n",
    "# silences_dataset = select_examples_based_labels(adult_chick_dataset_joined)\n",
    "\n",
    "#1\n",
    "new_labels_dict_1 = {0:'male_in', 1:'female_in', 2:'chick', 3:'male_bout', 4:'female_bout', 5:'flapping', 6: 'male_grunt', 7:'female_grunt', 8:'unk_grunt', 9:'adult_bout' }\n",
    "new_class_label =  'adult_bout'\n",
    "adult_chick_dataset_1, new_labels_dict_1= join_labels(['male_bout', 'female_bout'], dataset, labels_dict, new_labels_dict_1, new_class_label)\n",
    "\n",
    "\n",
    "#2\n",
    "new_labels_dict_2 = {0:'male_in', 1:'female_in', 2:'chick', 3:'male_bout', 4:'female_bout', 5:'flapping', 6: 'male_grunt', 7:'female_grunt', 8:'unk_grunt', 9:'adult_bout' , 10: 'adult_grunt'}\n",
    "new_class_label =  'adult_grunt'\n",
    "adult_chick_dataset_2, new_labels_dict_2= join_labels(['male_grunt', 'female_grunt', 'unk_grunt'], adult_chick_dataset_1, new_labels_dict_1, new_labels_dict_2, new_class_label)\n",
    "\n",
    "#3\n",
    "new_labels_dict_3 = {0:'adult_grunt', 1:'adult_bout', 2:'chick', }\n",
    "adult_chick_dataset_3, new_labels_dict_3= remove_label( adult_chick_dataset_2,new_labels_dict_2, new_labels_dict_3)\n",
    "\n",
    "\n",
    "\n",
    "# adult_chick_dataset_1, new_labels_dict = join_labels([0,1], dataset, labels_dict)\n",
    "# # this will have examples of adults chicks, plus all other classes (negatives) and silences\n",
    "\n",
    "# adult_chick_dataset, new_labels_dict = remove_labels([2,3,4,5,6,7,8], adult_chick_dataset_joined, new_labels_dict)\n",
    "# #this will have the same examples as before but only adults and cchicks are explicitly labeled . for binary classification!\n",
    "\n",
    "# adult_chick_dataset_only_positive = select_examples_based_labels(adult_chick_dataset, [0,1])\n",
    "# #this removes all examples of non chicks or non adults plus silences\n",
    "\n",
    "\n",
    "# adult_chick_dataset_negs_all_only = select_examples_based_labels[adult_chick_dataset]\n",
    "# # this removes all the examples of adults and chicks and leaves silences and negative classes examples\n",
    "# # ??\n",
    "\n",
    "# adult_chick_dataset_silences_only = select_examples_based_labels(adult_chick_dataset_joined)\n",
    "# # this will only contain silences! (no negatives nor positives!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'adult_grunt', 1: 'adult_bout', 2: 'chick'}\n",
      "(38049, 3)\n",
      "(3, 259)\n",
      "{0: 'male_in', 1: 'female_in', 2: 'chick', 3: 'male_bout', 4: 'female_bout', 5: 'flapping', 6: 'male_grunt', 7: 'female_grunt', 8: 'unk_grunt', 9: 'adult_bout', 10: 'adult_grunt'}\n",
      "(38049, 3)\n",
      "(11, 259)\n",
      "{0: 'male_in', 1: 'female_in', 2: 'chick', 3: 'male_bout', 4: 'female_bout', 5: 'flapping', 6: 'male_grunt', 7: 'female_grunt', 8: 'unk_grunt', 9: 'adult_bout'}\n",
      "(38049, 3)\n",
      "(10, 259)\n",
      "{0: 'male_in', 1: 'female_in', 2: 'chick', 3: 'male_bout', 4: 'female_bout', 5: 'flapping', 6: 'male_grunt', 7: 'female_grunt', 8: 'unk_grunt'}\n",
      "(38049, 3)\n",
      "(9, 259)\n"
     ]
    }
   ],
   "source": [
    "# verify:\n",
    "\n",
    "print(new_labels_dict_3)\n",
    "print(adult_chick_dataset_3.shape)\n",
    "print(adult_chick_dataset_3[0,-1].shape)\n",
    "\n",
    "\n",
    "print(new_labels_dict_2)\n",
    "print(adult_chick_dataset_2.shape)\n",
    "print(adult_chick_dataset_2[0,-1].shape)\n",
    "\n",
    "print(new_labels_dict_1)\n",
    "print(adult_chick_dataset_1.shape)\n",
    "print(adult_chick_dataset_1[0,-1].shape)\n",
    "\n",
    "print(labels_dict)\n",
    "print(dataset.shape)\n",
    "print(dataset[0,-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = dataset[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset_test[:,-1].shape[0]):\n",
    "    dataset_test[:,-1][i][1, 0:100] = 1\n",
    "    dataset_test[:,-1][i][4, 50:200] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test functions!\n",
    "new_labels_dict = labels_dict\n",
    "new_labels_dict[9] = 'testing!'\n",
    "new_class_label =  'testing!'\n",
    "test_dataset, labels_dict_result = join_labels(['female_in', 'female_bout'], dataset_test, labels_dict, new_labels_dict, new_class_label)\n",
    "\n",
    "\n",
    "new_labels_dict2 = {0:'testing!', 1:'male_bout', 2: 'female_in'}\n",
    "test_dataset_removed, last_labels_dict = remove_label(test_dataset,new_labels_dict, new_labels_dict2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.shape)\n",
    "print(test_dataset[0,-1].shape)\n",
    "print(dataset_test[0,-1].shape)\n",
    "print(labels_dict_result)\n",
    "# print(dataset_test[0,-1][0])\n",
    "# print(test_dataset[0,-1][0])\n",
    "\n",
    "# print(dataset_test[0,-1][4])\n",
    "print(test_dataset[0,-1][4])\n",
    "\n",
    "# print(dataset_test[0,-1][1])\n",
    "print(test_dataset[0,-1][1])\n",
    "\n",
    "print('resu;lt joining rows 1 and 4:')\n",
    "print(test_dataset[0,-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset_removed.shape)\n",
    "print(test_dataset_removed[0,-1].shape)\n",
    "print(dataset_test[0,-1].shape)\n",
    "print(test_dataset[0,-1].shape)\n",
    "print(last_labels_dict)\n",
    "# print(dataset_test[0,-1][0])\n",
    "# print(test_dataset[0,-1][0])\n",
    "\n",
    "# print(dataset_test[0,-1][4])\n",
    "print(test_dataset_removed[0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(9, 259)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(259,)\n",
      "[5. 5. 5. 5. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(5, 259)\n"
     ]
    }
   ],
   "source": [
    "ex_label_mat = dataset[1741,2]\n",
    "print(ex_label_mat)\n",
    "print(ex_label_mat.shape)\n",
    "\n",
    "new_row = np.sum(ex_label_mat[[1,2,3,4], :],0)\n",
    "print(new_row)\n",
    "print(new_row.shape)\n",
    "\n",
    "new_row[0:5] = 5\n",
    "print(new_row)\n",
    "\n",
    "new_row = np.divide(new_row, new_row, out=np.zeros_like(new_row), where=new_row!=0)\n",
    "print(new_row)\n",
    "\n",
    "\n",
    "new_ex_label_mat = ex_label_mat\n",
    "new_ex_label_mat = np.delete(new_ex_label_mat,[1,2,3,4], axis = 0)\n",
    "print(new_ex_label_mat)\n",
    "print(new_ex_label_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "dataset = [] # [dt_id, spectrogram, labelmatrix]\n",
    "\n",
    "for audio_file in tqdm(os.listdir(audio_path), desc='load_audio'):\n",
    "    print('load audio')\n",
    "    dataset_per_file = []\n",
    "    y, sr = librosa.load(audio_path+audio_file, sr=sample_rate)\n",
    "    length = int(len(y) / sr) #seconds\n",
    "    remainder = length % segment_size\n",
    "    #     import pdb; pdb.set_trace()\n",
    "\n",
    "    audio_id = audio_file[:-4]\n",
    "\n",
    "    raw_annotation_file = audio_id  + '_a.csv'\n",
    "\n",
    "    processed_annotations = process_raw_annotations_file(raw_annotation_file, annotations_path, labels_dict)    \n",
    "\n",
    "    for t in tqdm(range(0, length - remainder - segment_size, slide),\n",
    "                  desc='create_spectros'):\n",
    "        start = t\n",
    "    #         print('start', str(start))\n",
    "        stop = t + segment_size\n",
    "\n",
    "        print('start in frames', str(sr*start))\n",
    "        print('stop in frames: ', str((sr*stop)))\n",
    "\n",
    "        current_y = y[sr*start:(sr*stop)]\n",
    "        # create spectrogram\n",
    "        spectro = librosa.feature.melspectrogram(y=current_y, sr=sr, n_mels=mels,\n",
    "                                                 fmax=sr/2)\n",
    "\n",
    "        dt_id = audio_id + '_' + str(start) + 's_to' + str(stop) + 's'\n",
    "        print(dt_id)\n",
    "\n",
    "        label_matrix = get_label_matrix_per_segment(start, stop, sr, timesteps, timesteps_per_second, processed_annotations, labels_dict )\n",
    "        dataset_per_file.append([dt_id, spectro, label_matrix])\n",
    "        dataset.append([dt_id, spectro, label_matrix])\n",
    "        \n",
    "    \n",
    "    #save data processed for this file\n",
    "    d_array = np.asarray(dataset_per_file)\n",
    "    np.save(save_path+audio_id, d_array)\n",
    "\n",
    "data_array = np.asarray(dataset)\n",
    "np.save(save_path+'data_25_03', data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.floor(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for file in os.listdir('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/'):\n",
    "#     print(file)\n",
    "    data = np.load('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/' + file, allow_pickle=True)\n",
    "#     print(data.shape)\n",
    "    dataset.extend(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_array = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38049, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/ines/Dropbox/QMUL/PHD/manx_shearwaters/data/data_processed/dataset_25_03.npy', dataset_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
